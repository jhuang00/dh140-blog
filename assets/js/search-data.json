{
  
    
        "post0": {
            "title": "DH140 Project: Exploring the Surveillance Dataset",
            "content": "Digital Humanities 140 Project: Exploring the Surveillance Dataset . Project Introduction . Research Question: How is law-enforcing surveillance technology implemented in today&#39;s world? . The concept of surveillance seems to be an enticing topic by nature – humans are easily interested in knowing how they are being watched. Surveillance technology implemented by governmental agencies can be a double-edged sword: on the one hand, it helps departments like the police greatly in increasing their efficiency and effectiveness in resolving crimes and protecting other citizens; on the other hand, its presence constantly incites discussions and concerns for privacy. I am really interested in learning how surveillance technologies were adopted in the context of law enforcement in these years in the United States. What are the popular surveillance technologies used? What are the primary context in which they are used? What are their effectiveness and drawback? . This topic is tied to both sides, the implementers and the ones surveillance is implemented upon, who are the majority of people living in the U.S. Through exploring datasets with analyses and visualizations, this project could suggest how surveillance technologies were implemented and whether it has been an effective means for regulation. This could potentially give insight into issues like whether the benefit of surveillance technology outweighs the privacy concerns, or vice versa. . Data Sources . The main dataset I will be using for this project is the Atlas of Surveillance dataset, which holds information on surveillance technologies deployed by law enforcement in communities across the United States. The dataset includes instances of the adoption of various surveillance technology by law enforcement agencies. I might also use supplemental datasets to dig deeper into various kinds of surveillance methods, such as using drones or face recognition technology. For example, the Who Has Your Face? dataset provides information on which governmental agencies can access face recognition images, which is helpful in understanding how these agencies use this surveillance technology and the accessibities to these privacy-concerning databases. . Scope . In the analysis portion of the project, I will explore the variety of Law Enforcement Administration and Organizations (LEA) that use surveillance technologies, the variety of types of surveillance technologies used in different agencies, how many of the law enforcement agencies of each state has implemented surveillance technologies, etc. I will use a variety of visualizations to visualize the outcome of the datasets, such as bar plots, scatterplots, bubble plots, etc. An example would be to visualize the type of surveillance technology implemented categorized by the type of LEA. Another instance would be to visualize the use of a surveillance technology regionally across the country. . Conclusion . By the end of this project, I hope to gain a deeper understanding of how surveillance technologies are used today in the context of law enforcement. Surveillance is an evolving and convoluted topic in the modern era, as technological development is happening at an increasingly rapid speed. Questions arise along with the advancements: where to draw the line between protection and privacy? This could allow us to gain insight into the effectiveness of law-enforcing surveillance, and hence, to gain an idea of how to best protect citizens living in this society. . Introduction of the Data . import pandas as pd import matplotlib.pyplot as plt . # import Atlas of Surveillance csv file and turn into dataframe aos_raw_df = pd.read_csv(&quot;Atlas of Surveillance.csv&quot;) . # select useful columns for dataframe aos_df = aos_raw_df.iloc[:,1:10] . # clean dataset and resolve inconsistencies aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;NB&#39;],&#39;NE&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;Montana&#39;],&#39;MT&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;Idaho&#39;],&#39;ID&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;US Virgin Islands&#39;],&#39;VI&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;Puerto Rico&#39;],&#39;PR&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;FL &#39;],&#39;FL&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;WI &#39;],&#39;WI&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;GA &#39;],&#39;GA&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;OH &#39;],&#39;OH&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;AL &#39;],&#39;AL&#39;) aos_df[&#39;State&#39;] = aos_df[&#39;State&#39;].replace([&#39;IL &#39;],&#39;IL&#39;) aos_df[&#39;Type of LEA&#39;] = aos_df[&#39;Type of LEA&#39;].replace([&#39;Police &#39;,&#39;Poilice&#39;],&#39;Police&#39;) aos_df[&#39;Type of LEA&#39;] = aos_df[&#39;Type of LEA&#39;].replace([&#39;Security &#39;],&#39;Security&#39;) aos_df[&#39;Type of LEA&#39;] = aos_df[&#39;Type of LEA&#39;].replace([&#39;Wildlife &#39;],&#39;Wildlife&#39;) aos_df[&#39;Type of LEA&#39;] = aos_df[&#39;Type of LEA&#39;].replace([&#39;State Police &#39;],&#39;State Police&#39;) aos_df[&#39;Type of Juris&#39;] = aos_df[&#39;Type of Juris&#39;].replace([&#39;University &#39;],&#39;University&#39;) aos_df[&#39;Type of Juris&#39;] = aos_df[&#39;Type of Juris&#39;].replace([&#39;Municipal &#39;],&#39;Municipal&#39;) aos_df[&#39;Type of Juris&#39;] = aos_df[&#39;Type of Juris&#39;].replace([&#39;School &#39;],&#39;School&#39;) . . # look at dataframe aos_df.head() . City County State Agency Type of LEA Summary Type of Juris Technology Vendor . 0 Woodstock | Shenandoah County | VA | Woodstock Police Department | Police | The Woodstock Police Department has used body-... | Municipal | Body-worn Cameras | VML Insurance Programs | . 1 Rockford | Ogle County, Winnebago County | IL | Rockford Police Department | Police | The Rockford Police Department spent $310,000 ... | Municipal | Gunshot Detection | ShotSpotter | . 2 Atlanta | DeKalb County, Fulton County | GA | Atlanta Police Department | Police | The Atlanta Police Department began using Shot... | Municipal | Gunshot Detection | ShotSpotter | . 3 Peoria | Peoria County | IL | Peoria Police Department | Police | The Peoria Police Department began using ShotS... | Municipal | Gunshot Detection | ShotSpotter | . 4 Goldsboro | Wayne County | NC | Goldsboro Police Department | Police | The Goldsboro Police Department uses ShotSpott... | Municipal | Gunshot Detection | ShotSpotter | . # get number of columns and rows aos_df.shape . (8184, 9) . # get column names aos_df.columns . Index([&#39;City&#39;, &#39;County&#39;, &#39;State&#39;, &#39;Agency&#39;, &#39;Type of LEA&#39;, &#39;Summary&#39;, &#39;Type of Juris&#39;, &#39;Technology&#39;, &#39;Vendor&#39;], dtype=&#39;object&#39;) . # get summary information of the dataset aos_df.describe() . City County State Agency Type of LEA Summary Type of Juris Technology Vendor . count 8183 | 8090 | 8183 | 8184 | 8181 | 8184 | 8184 | 8184 | 4868 | . unique 3529 | 1236 | 54 | 4694 | 55 | 8055 | 22 | 12 | 203 | . top Madison | Cook County | CA | Jefferson County Sheriff&#39;s Office | Police | The District Attorneys Council has installed R... | Municipal | Body-worn Cameras | Ring | . freq 28 | 137 | 838 | 20 | 6222 | 27 | 5785 | 2784 | 1903 | . Type of LEA . # get frequency of types of LEA aos_lea_freq = aos_df[&#39;Type of LEA&#39;].value_counts() . # plot bar graph aos_lea_freq.plot(kind=&#39;bar&#39;, figsize=(15,5), title=&#39;Frequency of Types of LEA&#39;, color=&#39;steelblue&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Frequency of Types of LEA&#39;}&gt; . # plot bar graph without the two highest frequency LEAs for visability aos_lea_freq_trimmed = aos_lea_freq[2:] aos_lea_freq_trimmed.plot(kind=&#39;bar&#39;, figsize=(15,5), title=&#39;Frequency of Types of LEA (trimmed)&#39;, color=&#39;steelblue&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Frequency of Types of LEA (trimmed)&#39;}&gt; . Type of Jurisdiction . # get frequency of types of juris aos_juris_freq = aos_df[&#39;Type of Juris&#39;].value_counts() . print(aos_juris_freq) . Municipal 5785 County 1725 University 249 State 178 Regional 132 School District 21 Federal 20 Tribal 17 Territory 12 Parish 10 Airport 8 Statewide 7 Transit 4 Cross-jurisdictional 4 School 3 Township 2 Special District 2 Police 1 Port 1 Borough 1 Transity 1 Transportation 1 Name: Type of Juris, dtype: int64 . # plot bar graph aos_juris_freq.plot(kind=&#39;bar&#39;, figsize=(10,5), title=&#39;Frequency of Types of Juris&#39;, color=&#39;mediumseagreen&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Frequency of Types of Juris&#39;}&gt; . Technology . # get frequency of technology aos_tech_freq = aos_df[&#39;Technology&#39;].value_counts() . print(aos_tech_freq) . Body-worn Cameras 2784 Ring/Neighbors Partnership 1903 Drones 1181 Automated License Plate Readers 951 Camera Registry 413 Face Recognition 384 Predictive Policing 160 Gunshot Detection 133 Real-Time Crime Center 86 Fusion Center 79 Cell-site Simulator 70 Video Analytics 40 Name: Technology, dtype: int64 . # plot bar graph aos_tech_freq.plot(kind=&#39;bar&#39;, figsize=(8,5), title=&#39;Frequency of Technology&#39;, color=&#39;slateblue&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Frequency of Technology&#39;}&gt; . Vendor . # get frequency of vendors aos_vendor_freq = aos_df[&#39;Vendor&#39;].value_counts() . # filter vendors with frequencies no less than 5 times aos_vendor_trimmed_freq = aos_vendor_freq[aos_vendor_freq &gt;= 5] . print(aos_vendor_trimmed_freq) . Ring 1903 DJI 598 Axon 435 Vigilant Solutions 295 Idemia 256 Motorola Solutions 180 ShotSpotter 123 IBM 98 Wolfcom 91 Flock Safety 67 WatchGuard 59 Utility 55 NDI Recognition Systems 48 Neology/PIPS 35 Yuneec 34 ELSAG 33 Harris Corp. 27 Rekor Systems 27 BriefCam 25 Geolitica 23 Selex 22 Clearview AI 21 Coban 18 BodyWorn (Utility, Inc.) 16 Flock 16 VieVu 14 DataWorks Plus 12 Vigilant Solutions, Neology/PIPS 12 PIPS 9 Autel Robotics 8 Draganfly Innovations 7 Elsag 7 Project NOLA 7 Digital Ally 7 Panasonic 7 Aeryon Labs 7 Shotspotter 6 Physical Sciences 6 Leptron 6 NEC 5 Name: Vendor, dtype: int64 . # plot bar graph aos_vendor_trimmed_freq.plot(kind=&#39;bar&#39;, figsize=(12,5), title=&#39;Frequency of Selected Vendor&#39;, color=&#39;yellowgreen&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Frequency of Selected Vendor&#39;}&gt; . Analysis . aos_state_freq = aos_df[&#39;State&#39;].value_counts() . aos_state_freq.plot(kind=&#39;bar&#39;, figsize=(20,5), title=&#39;No. of Instances in States&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;No. of Instances in States&#39;}&gt; . The top three states are California, Florida, and New Jersey. . Note that this data is not normalized; i.e. the size and population difference between the states are not accounted for. . aos_state_freq . CA 838 FL 761 NJ 740 TX 475 IL 420 WI 410 GA 278 SC 270 OH 256 NY 249 MN 227 CO 227 MI 198 TN 183 PA 171 VA 170 NC 169 IN 155 AZ 155 MO 151 AL 113 OK 112 CT 105 MS 104 MA 102 MD 102 WA 96 OR 89 KY 84 KS 76 NV 69 LA 61 IA 60 NM 57 AR 56 UT 54 ID 48 NE 46 ME 32 ND 27 DE 25 WY 23 WV 18 MT 18 NH 16 SD 15 RI 15 AK 13 PR 12 HI 11 VT 8 DC 8 VI 4 GU 1 Name: State, dtype: int64 . . Explore LEA in States . # find the frequency of the most frequent type of LEA aos_df[&#39;Type of LEA&#39;].value_counts()[0] . 6222 . # find the most frequent type of LEA aos_df[&#39;Type of LEA&#39;].value_counts().reset_index()[&#39;index&#39;][0] . &#39;Police&#39; . # determine no. of cases with police LEA for each state in the US state_leaPolice_count = aos_df[aos_df[&#39;Type of LEA&#39;] == &#39;Police&#39;][&#39;State&#39;].value_counts() . # plot bar graph state_leaPolice_count.plot(kind=&#39;bar&#39;, figsize=(12,5), title=&#39;Number of Cases with Police LEA Per State&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Number of Cases with Police LEA Per State&#39;}&gt; . Explore Type of Technology in States . # create dataframe that stores the count of kinds of technology of each state state_tech_count = aos_df.groupby(&#39;Technology&#39;)[&#39;State&#39;].value_counts().reset_index(name=&#39;counts&#39;) . # create bubble plot (bubble size with &quot;s&quot;) plt.scatter(&#39;State&#39;, &#39;Technology&#39;, s=&#39;counts&#39;, alpha=0.8, data=state_tech_count) plt.xlabel(&quot;States&quot;, size=16) plt.ylabel(&quot;Technology&quot;, size=16) plt.title(&quot;No. of Usage of Technology in Each State&quot;, size=18) plt.gcf().set_size_inches((20, 6)) . Some most common technology uses are ring/neighbors partnership, body-worn cameras, automated license plate readers, and drones. From this graph, we can also see that some technology is extensively used in particular areas. For example, face recognition is used heavily in Florida but less in other states. In New Jersey, most cases are done with body-worn cameras while other kinds of technology are not as commonly used. . What percentage of the cases in New Jersey are with body-worn cameras instead of other technology? . # isolate dataframe of technology in New Jersey stateNJ_tech_count = state_tech_count[state_tech_count[&#39;State&#39;] == &#39;NJ&#39;] # find percentage of usage of body-worn camera in NJ int(stateNJ_tech_count[stateNJ_tech_count[&#39;Technology&#39;] == &#39;Body-worn Cameras&#39;][&#39;counts&#39;])/sum(stateNJ_tech_count[&#39;counts&#39;]) . 0.7216216216216216 . # find the general percentage of body-worn cameras in all the states aos_df[&#39;Technology&#39;].value_counts()[&#39;Body-worn Cameras&#39;]/sum(aos_df[&#39;Technology&#39;].value_counts()) . 0.34017595307917886 . Nearly 3/4th (72%) of the cases in New Jersey use body-worn cameras. However, among all the states, the percentage of body-worn cameras is only 34%. . # find percentage of body-worn cameras among all technology in each state state_techBWC_percentage = state_tech_count[state_tech_count[&#39;Technology&#39;] == &#39;Body-worn Cameras&#39;].groupby(&#39;State&#39;).sum() / state_tech_count.groupby(&#39;State&#39;).sum() . # sort values from high to low state_techBWC_percentage = state_techBWC_percentage.sort_values(&#39;counts&#39;, ascending=False) # turn NaN to 0 state_techBWC_percentage[&#39;counts&#39;] = state_techBWC_percentage[&#39;counts&#39;].replace([float(&#39;NaN&#39;)],0) . state_techBWC_percentage[&#39;counts&#39;] . State PR 0.750000 WY 0.739130 NJ 0.721622 MS 0.701923 WI 0.675610 SC 0.655556 SD 0.600000 CO 0.594714 NM 0.543860 WV 0.500000 VA 0.476471 OK 0.455357 AZ 0.451613 MT 0.444444 NV 0.434783 ME 0.406250 AR 0.375000 VT 0.375000 NE 0.369565 KY 0.357143 MI 0.323232 ID 0.312500 AK 0.307692 ND 0.296296 TX 0.292632 GA 0.291367 MO 0.278146 IL 0.273810 IN 0.270968 LA 0.262295 VI 0.250000 IA 0.250000 NH 0.250000 NC 0.248521 OR 0.235955 FL 0.224704 KS 0.223684 NY 0.212851 RI 0.200000 CA 0.184964 PA 0.175439 OH 0.160156 DE 0.160000 CT 0.142857 DC 0.125000 AL 0.123894 TN 0.114754 UT 0.111111 MN 0.105727 MD 0.098039 HI 0.090909 WA 0.083333 MA 0.058824 GU 0.000000 Name: counts, dtype: float64 . . # create bar plot state_techBWC_percentage.plot(kind=&#39;bar&#39;, figsize=(12,6)) . &lt;AxesSubplot:xlabel=&#39;State&#39;&gt; . Now, let&#39;s explore the top types of technology use. The top five are Body-worn Cameras, Ring/Neighbors Partnership, Drones, Automated License Plate Readers, and Camera Registry. . What is the relationship of the number of technology use in each state? . # create state list state_list = list(state_tech_count[&#39;State&#39;].unique()) # create empty lists for technology types bwc_list = [] rnp_list = [] drone_list = [] alpr_list = [] cr_list = [] for i in state_list: try: rnp_list.append(state_tech_count.loc[(state_tech_count[&#39;State&#39;] == i) &amp; (state_tech_count[&#39;Technology&#39;] == &#39;Ring/Neighbors Partnership&#39;),&#39;counts&#39;].values[0]) except: rnp_list.append(0) try: bwc_list.append(state_tech_count.loc[(state_tech_count[&#39;State&#39;] == i) &amp; (state_tech_count[&#39;Technology&#39;] == &#39;Body-worn Cameras&#39;),&#39;counts&#39;].values[0]) except: bwc_list.append(0) try: drone_list.append(state_tech_count.loc[(state_tech_count[&#39;State&#39;] == i) &amp; (state_tech_count[&#39;Technology&#39;] == &#39;Drones&#39;),&#39;counts&#39;].values[0]) except: drone_list.append(0) try: alpr_list.append(state_tech_count.loc[(state_tech_count[&#39;State&#39;] == i) &amp; (state_tech_count[&#39;Technology&#39;] == &#39;Automated License Plate Readers&#39;),&#39;counts&#39;].values[0]) except: alpr_list.append(0) try: cr_list.append(state_tech_count.loc[(state_tech_count[&#39;State&#39;] == i) &amp; (state_tech_count[&#39;Technology&#39;] == &#39;Camera Registry&#39;),&#39;counts&#39;].values[0]) except: cr_list.append(0) . state_tech_df = pd.DataFrame({&#39;State&#39;:state_list, &#39;RNP&#39;:rnp_list, &#39;BWC&#39;:bwc_list, &#39;Drones&#39;:drone_list, &#39;ALPR&#39;:alpr_list, &#39;CR&#39;:cr_list}) . state_tech_df.head() . State RNP BWC Drones ALPR CR . 0 CA | 151 | 155 | 113 | 258 | 75 | . 1 FL | 135 | 171 | 52 | 77 | 18 | . 2 TX | 128 | 139 | 75 | 58 | 35 | . 3 GA | 59 | 81 | 41 | 57 | 22 | . 4 MN | 32 | 24 | 99 | 52 | 6 | . As we can notice, the most prevalent technology use in surveillance is camera-related technology. Body-worn cameras are devices that record interactions between community members (e.g., the public, suspects, and victims) and officers for law enforcement purposes. Ring/Neighborhood partnership is an app-based surveillance service which uses doorbell cameras and other home surveillance devices to record video footages, alert, and report incidents. The service is provided by Ring Inc., which has signed agreements with more than 1,300 law enforcement agencies to promote its products. . With them both being camera-related technology, do we see a similar pattern in the number of use cases in each state? . What is the correlation between the number of cases of body-worn cameras and of ring/neighbor partnership in each state? . import numpy as np from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score . np.corrcoef(state_tech_df[&#39;RNP&#39;], state_tech_df[&#39;BWC&#39;])[1][0] . 0.6430373152435569 . The correlation coefficient is approximately 0.64. Therefore, we have found a moderately positive correlation between the number of body-worn cameras and Ring&#39;s neighbor partnerships. . # create scatter plot state_tech_df.plot.scatter(x=&#39;RNP&#39;, y=&#39;BWC&#39;) . &lt;AxesSubplot:xlabel=&#39;RNP&#39;, ylabel=&#39;BWC&#39;&gt; . # plot linear regression X = state_tech_df[[&#39;RNP&#39;]] y = state_tech_df[[&#39;BWC&#39;]] . reg = LinearRegression().fit(X, y) . reg.coef_ . array([[1.24865797]]) . reg.intercept_ . array([7.55192375]) . ytrain = reg.intercept_ + reg.coef_ * X . plt.plot(X, y, &#39;ro&#39;, X, ytrain); . Now, determine the linear correlation between each of the top types of technology. . np.corrcoef(state_tech_df[&#39;RNP&#39;], state_tech_df[&#39;Drones&#39;])[1][0] . 0.6818957089764259 . np.corrcoef(state_tech_df[&#39;RNP&#39;], state_tech_df[&#39;ALPR&#39;])[1][0] . 0.5722789126534248 . np.corrcoef(state_tech_df[&#39;RNP&#39;], state_tech_df[&#39;CR&#39;])[1][0] . 0.6752423882711164 . np.corrcoef(state_tech_df[&#39;BWC&#39;], state_tech_df[&#39;Drones&#39;])[1][0] . 0.3376245559492976 . np.corrcoef(state_tech_df[&#39;BWC&#39;], state_tech_df[&#39;ALPR&#39;])[1][0] . 0.2658723292941826 . np.corrcoef(state_tech_df[&#39;BWC&#39;], state_tech_df[&#39;CR&#39;])[1][0] . 0.3638136019553725 . np.corrcoef(state_tech_df[&#39;Drones&#39;], state_tech_df[&#39;ALPR&#39;])[1][0] . 0.7791349774873542 . np.corrcoef(state_tech_df[&#39;Drones&#39;], state_tech_df[&#39;CR&#39;])[1][0] . 0.7479069660509468 . np.corrcoef(state_tech_df[&#39;ALPR&#39;], state_tech_df[&#39;CR&#39;])[1][0] . 0.8891825370752605 . The pair with the least correlation is body-worn cameras and automated license plate readers. The correlation coefficient is approximately 0.27. . state_tech_df.plot.scatter(x=&#39;BWC&#39;, y=&#39;ALPR&#39;) . &lt;AxesSubplot:xlabel=&#39;BWC&#39;, ylabel=&#39;ALPR&#39;&gt; . X = state_tech_df[[&#39;BWC&#39;]] y = state_tech_df[[&#39;ALPR&#39;]] . reg = LinearRegression().fit(X, y) . reg.coef_ . array([[0.11394637]]) . reg.intercept_ . array([11.7365428]) . ytrain = reg.intercept_ + reg.coef_ * X . plt.plot(X, y, &#39;ro&#39;, X, ytrain); . The pair with the greatest correlation is automated license plate readers and camera registry. The correlation coefficient is approximately 0.89. . state_tech_df.plot.scatter(x=&#39;ALPR&#39;, y=&#39;CR&#39;) . &lt;AxesSubplot:xlabel=&#39;ALPR&#39;, ylabel=&#39;CR&#39;&gt; . X = state_tech_df[[&#39;ALPR&#39;]] y = state_tech_df[[&#39;CR&#39;]] . reg = LinearRegression().fit(X, y) . reg.coef_ . array([[0.28159203]]) . reg.intercept_ . array([2.68899961]) . ytrain = reg.intercept_ + reg.coef_ * X . plt.plot(X, y, &#39;ro&#39;, X, ytrain); . # calculate mean squared error mean_squared_error(y, ytrain) . 28.706037077067716 . # calculate R-squared value r2_score(y, ytrain) . 0.7906455842395963 . Since most data points are rather clustered in the bottom left corner of the scatter plot, we can omit data points that are far from the cluster to better observe the pattern. . state_tech_trimmed_df = state_tech_df[state_tech_df[&#39;ALPR&#39;] &lt; 200] . np.corrcoef(state_tech_trimmed_df[&#39;ALPR&#39;], state_tech_trimmed_df[&#39;CR&#39;])[1][0] . 0.6656582942727832 . The correlation coefficient has become smaller after the dataset is trimmed; however, there is still a positive relationship. . reg = LinearRegression().fit(state_tech_trimmed_df[[&#39;ALPR&#39;]], state_tech_trimmed_df[[&#39;CR&#39;]]) ytrain = reg.intercept_ + reg.coef_ * state_tech_trimmed_df[[&#39;ALPR&#39;]] plt.plot(state_tech_trimmed_df[[&#39;ALPR&#39;]], state_tech_trimmed_df[[&#39;CR&#39;]], &#39;ro&#39;, state_tech_trimmed_df[[&#39;ALPR&#39;]], ytrain); . From these correlational analysis, we can see that for the top 5 technology types, there is a general positive relationship between the number of use cases in each state, which shows that if a state has more number of use cases for a particular technology type than another state, it is more likely than not that the state also has more number of use cases for another technology type. Note that this is speaking from a general sense, so it is describing a general trend rather than focusing on specific states. Between some technology types, such as body-worn cameras and automated license plate readers, the positive correlation is weak; however, between most technology pairs, there is at least a moderate positive correlation. .",
            "url": "https://jhuang00.github.io/dh140-blog/fastpages/jupyter/2022/03/14/project.html",
            "relUrl": "/fastpages/jupyter/2022/03/14/project.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Assignment 09 - Data analysis communication",
            "content": "Assignment 05: Web Scraping . Use requests and BeautifulSoup to make a list of all the CORGIS datasets . # import requests library import requests # import BeautifulSoup from bs4 import BeautifulSoup # import pandas import pandas as pd # import matplotlib import matplotlib.pyplot as plt . . # use requests to issue HTTP request to the website response = requests.get(&#39;https://corgis-edu.github.io/corgis/csv/&#39;) . # save all the html in a string variable html_string = response.text # use BeautifulSoup to create a new object to search for HTML tags document = BeautifulSoup(html_string, &quot;html.parser&quot;) # use the &quot;find&quot; method of the &quot;document&quot; variable to look for the tag &quot;h3&quot; and make a list h3_list = [] for i in document.find_all(&#39;h3&#39;): h3_list.append(i.text) . # inspect the CORGIS datasets list h3_list . [&#39;Aids&#39;, &#39;Airlines&#39;, &#39;Billionaires&#39;, &#39;Broadway&#39;, &#39;Business Dynamics&#39;, &#39;Cancer&#39;, &#39;Cars&#39;, &#39;Classics&#39;, &#39;Construction Permits&#39;, &#39;Construction Spending&#39;, &#39;County Demographics&#39;, &#39;Covid&#39;, &#39;Drugs&#39;, &#39;Earthquakes&#39;, &#39;Election&#39;, &#39;Electricity&#39;, &#39;Emissions&#39;, &#39;Energy&#39;, &#39;Finance&#39;, &#39;Food&#39;, &#39;Food Access&#39;, &#39;Global Development&#39;, &#39;Graduates&#39;, &#39;Health&#39;, &#39;Hospitals&#39;, &#39;Hydropower&#39;, &#39;Ingredients&#39;, &#39;Injuries&#39;, &#39;Labor&#39;, &#39;Medal Of Honor&#39;, &#39;Music&#39;, &#39;Opioids&#39;, &#39;Police Shootings&#39;, &#39;Publishers&#39;, &#39;Real Estate&#39;, &#39;Retail Services&#39;, &#39;School Scores&#39;, &#39;Skyscrapers&#39;, &#39;Slavery&#39;, &#39;State Crime&#39;, &#39;State Demographics&#39;, &#39;State Fragility&#39;, &#39;Suicide Attacks&#39;, &#39;Supreme Court&#39;, &#39;Tate&#39;, &#39;Video Games&#39;, &#39;Weather&#39;, &#39;Wind Turbines&#39;] . . Write a function that takes an element from the list of CORGIS datasets, searches the respective CORGIS page for the CSV download link, and returns a Pandas dataframe . # define pdfcorgis(), which takes a CORGIS dataset and returns a Pandas dataframe def pdfcorgis(a): # convert a to lowercase x = a.lower() # get the website&#39;s HTML response = requests.get(&#39;https://corgis-edu.github.io/corgis/csv/&#39; + x + &#39;/&#39;) html_string = response.text # use BeautifulSoup to create a new object to search for HTML tags document = BeautifulSoup(html_string, &quot;html.parser&quot;) # use for loop to loop over all the HTML elements that have the tag &quot;a&quot; (links) for i in document.find_all(&quot;a&quot;): # if i has the attribute &quot;download&quot; if i.has_attr(&#39;download&#39;): # extract link link = &#39;https://corgis-edu.github.io/corgis/datasets/csv/&#39; + x + &#39;/&#39; + i.text.strip() corgisdf = pd.read_csv(link) return corgisdf . # test pdfcorgis() with &quot;Classics&quot; pdfcorgis(&quot;Classics&quot;) . bibliography.congress classifications bibliography.languages bibliography.subjects bibliography.title bibliography.type metadata.downloads metadata.id metadata.rank metadata.url bibliography.author.birth ... metrics.sentiments.polarity metrics.sentiments.subjectivity metrics.statistics.average letter per word metrics.statistics.average sentence length metrics.statistics.average sentence per word metrics.statistics.characters metrics.statistics.polysyllables metrics.statistics.sentences metrics.statistics.syllables metrics.statistics.words . 0 PR | en | Sisters -- Fiction,Courtship -- Fiction,Social... | Pride and Prejudice | Text | 36576 | 1342 | 1 | https://www.gutenberg.org/ebooks/1342 | 1775 | ... | 0.136713 | 0.522239 | 4.83 | 18.0 | 0.05 | 586794 | 4603 | 6511 | 170648.1 | 121533 | . 1 PS | en | Mentally ill women -- Fiction,Feminist fiction... | The Yellow Wallpaper | Text | 26363 | 1952 | 2 | https://www.gutenberg.org/ebooks/1952 | 1860 | ... | 0.054174 | 0.534787 | 4.41 | 15.0 | 0.06 | 26769 | 102 | 385 | 7686.9 | 6067 | . 2 PZ,PR | en | Fantasy | Alice&#39;s Adventures in Wonderland | Text | 18882 | 11 | 3 | https://www.gutenberg.org/ebooks/11 | 1832 | ... | 0.041079 | 0.497276 | 4.65 | 17.0 | 0.06 | 122719 | 339 | 1501 | 33810.3 | 26389 | . 3 PR | en | Monsters -- Fiction;Frankenstein&#39;s monster (Fi... | Frankenstein; Or, The Modern Prometheus | Text | 17128 | 84 | 4 | https://www.gutenberg.org/ebooks/84 | 1797 | ... | 0.100902 | 0.539516 | 4.77 | 23.0 | 0.04 | 357604 | 2604 | 3239 | 106802.1 | 74959 | . 4 PT | en | Psychological fiction,Metamorphosis -- Fiction | Metamorphosis | Text | 15683 | 5200 | 5 | https://www.gutenberg.org/ebooks/5200 | 1883 | ... | 0.041997 | 0.479019 | 4.56 | 27.0 | 0.04 | 100372 | 397 | 800 | 28752.3 | 22022 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1001 NaN | en | NaN | The Reluctant Heroes | Text | 0 | 51483 | 1002 | https://www.gutenberg.org/ebooks/51483 | 1926 | ... | 0.076203 | 0.451757 | 4.68 | 11.0 | 0.09 | 32354 | 112 | 618 | 8824.5 | 6913 | . 1002 NaN | en | NaN | Film Truth; September, 1920 | Text | 0 | 51484 | 1003 | https://www.gutenberg.org/ebooks/51484 | 0 | ... | 0.143879 | 0.485782 | 5.02 | 17.0 | 0.06 | 45970 | 312 | 536 | 13080.6 | 9153 | . 1003 NaN | en | NaN | Othmar | Text | 0 | 51487 | 1004 | https://www.gutenberg.org/ebooks/51487 | 1839 | ... | 0.099478 | 0.548289 | 4.66 | 21.0 | 0.05 | 890918 | 4808 | 8921 | 258091.2 | 191182 | . 1004 NaN | en | NaN | Church History (Volumes 1-3) | Text | 0 | 51491 | 1005 | https://www.gutenberg.org/ebooks/51491 | 1809 | ... | 0.112242 | 0.440014 | 5.31 | 17.0 | 0.06 | 3883244 | 46730 | 41950 | 1083170.7 | 730715 | . 1005 NaN | en | NaN | The Uncensored Letters of a Canteen Girl | Text | 0 | 51495 | 1006 | https://www.gutenberg.org/ebooks/51495 | 0 | ... | 0.059623 | 0.435443 | 4.73 | 17.0 | 0.06 | 451687 | 2595 | 5580 | 130093.2 | 95496 | . 1006 rows × 38 columns . . Using dataframes returned by your new function, make a line plot, a bar plot, and a histogram plot . Line plot . # create Finance dataframe finance_df = pdfcorgis(&quot;Finance&quot;) . finance_df.head() . . State Year Totals.Capital outlay Totals.Revenue Totals.Expenditure Totals.General expenditure Totals.General revenue Totals.Insurance trust revenue Totals.Intergovernmental Totals.License tax ... Details.Welfare.Welfare Institution Total Expenditure Details.Natural Resources.Parks.Parks Total Expenditure Details.Transportation.Highways.Highways Total Expenditure Totals. Debt at end of fiscal year Details.Insurance benefits and repayments Details.Interest on debt Details.Interest on general debt Details.Miscellaneous general revenue Details.Other taxes Details.Police protection . 0 ALABAMA | 1992 | 664748 | 10536166 | 9650515 | 8788293 | 8910315 | 1473217 | 2737180 | 395202 | ... | 1853436 | 9728 | 694874 | 4128724 | 724852 | 280179 | 280179 | 607453 | 205227 | 77789 | . 1 ALABAMA | 1993 | 781952 | 11389335 | 10242374 | 9339796 | 9688246 | 1570768 | 2965310 | 377723 | ... | 2016935 | 11031 | 856228 | 4170084 | 761582 | 267648 | 267648 | 599988 | 224878 | 78320 | . 2 ALABAMA | 1994 | 767100 | 11599362 | 10815221 | 9922352 | 10014415 | 1454982 | 3077084 | 386771 | ... | 2167799 | 12053 | 883852 | 3853804 | 762811 | 250642 | 250642 | 643807 | 234592 | 86839 | . 3 ALABAMA | 1995 | 808001 | 12279726 | 11541881 | 10489513 | 10582838 | 1566923 | 3240417 | 480698 | ... | 2291264 | 10645 | 924411 | 3758726 | 912649 | 193752 | 193752 | 643469 | 232783 | 83482 | . 4 ALABAMA | 1996 | 760751 | 12741148 | 12126587 | 10991713 | 10894396 | 1710360 | 3347019 | 422841 | ... | 2325418 | 7788 | 881381 | 3645292 | 987710 | 216842 | 216842 | 649073 | 265426 | 86936 | . 5 rows × 31 columns . # line plot finance_df.groupby(&#39;Year&#39;)[&#39;Totals.Revenue&#39;].sum().plot(title=&#39;Total Revenue (1992-2019)&#39;, figsize=(8,8)) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Total Revenue (1992-2019)&#39;}, xlabel=&#39;Year&#39;&gt; . Bar plot . # create Airlines dataframe airlines_df = pdfcorgis(&quot;Airlines&quot;) . airlines_df.head() . . Airport.Code Airport.Name Time.Label Time.Month Time.Month Name Time.Year Statistics.# of Delays.Carrier Statistics.# of Delays.Late Aircraft Statistics.# of Delays.National Aviation System Statistics.# of Delays.Security ... Statistics.Flights.Delayed Statistics.Flights.Diverted Statistics.Flights.On Time Statistics.Flights.Total Statistics.Minutes Delayed.Carrier Statistics.Minutes Delayed.Late Aircraft Statistics.Minutes Delayed.National Aviation System Statistics.Minutes Delayed.Security Statistics.Minutes Delayed.Total Statistics.Minutes Delayed.Weather . 0 ATL | Atlanta, GA: Hartsfield-Jackson Atlanta Intern... | 2003/06 | 6 | June | 2003 | 1009 | 1275 | 3217 | 17 | ... | 5843 | 27 | 23974 | 30060 | 61606 | 68335 | 118831 | 518 | 268764 | 19474 | . 1 BOS | Boston, MA: Logan International | 2003/06 | 6 | June | 2003 | 374 | 495 | 685 | 3 | ... | 1623 | 3 | 7875 | 9639 | 20319 | 28189 | 24400 | 99 | 77167 | 4160 | . 2 BWI | Baltimore, MD: Baltimore/Washington Internatio... | 2003/06 | 6 | June | 2003 | 296 | 477 | 389 | 8 | ... | 1245 | 15 | 6998 | 8287 | 13635 | 26810 | 17556 | 278 | 64480 | 6201 | . 3 CLT | Charlotte, NC: Charlotte Douglas International | 2003/06 | 6 | June | 2003 | 300 | 472 | 735 | 2 | ... | 1562 | 14 | 7021 | 8670 | 14763 | 23379 | 23804 | 127 | 65865 | 3792 | . 4 DCA | Washington, DC: Ronald Reagan Washington National | 2003/06 | 6 | June | 2003 | 283 | 268 | 487 | 4 | ... | 1100 | 18 | 5321 | 6513 | 13775 | 13712 | 20999 | 120 | 52747 | 4141 | . 5 rows × 24 columns . # bar plot airlines_df.groupby(&#39;Airport.Code&#39;)[&#39;Statistics.Flights.Total&#39;].mean().sort_values().plot.barh(figsize=(8,8), title=&#39;Average Daily Number of Flights Per Airport&#39;, color=&#39;lightblue&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Average Daily Number of Flights Per Airport&#39;}, ylabel=&#39;Airport.Code&#39;&gt; . Histrogram . # create Food dataframe food_df = pdfcorgis(&quot;Food&quot;) . food_df.head() . . Category Description Nutrient Data Bank Number Data.Alpha Carotene Data.Beta Carotene Data.Beta Cryptoxanthin Data.Carbohydrate Data.Cholesterol Data.Choline Data.Fiber ... Data.Major Minerals.Phosphorus Data.Major Minerals.Potassium Data.Major Minerals.Sodium Data.Major Minerals.Zinc Data.Vitamins.Vitamin A - RAE Data.Vitamins.Vitamin B12 Data.Vitamins.Vitamin B6 Data.Vitamins.Vitamin C Data.Vitamins.Vitamin E Data.Vitamins.Vitamin K . 0 Milk | Milk, human | 11000000 | 0 | 7 | 0 | 6.89 | 14 | 16.0 | 0.0 | ... | 14 | 51 | 17 | 0.17 | 61 | 0.05 | 0.011 | 5.0 | 0.08 | 0.3 | . 1 Milk | Milk, NFS | 11100000 | 0 | 4 | 0 | 4.87 | 8 | 17.9 | 0.0 | ... | 103 | 157 | 39 | 0.42 | 59 | 0.56 | 0.060 | 0.1 | 0.03 | 0.2 | . 2 Milk | Milk, whole | 11111000 | 0 | 7 | 0 | 4.67 | 12 | 17.8 | 0.0 | ... | 101 | 150 | 38 | 0.41 | 32 | 0.54 | 0.061 | 0.0 | 0.05 | 0.3 | . 3 Milk | Milk, low sodium, whole | 11111100 | 0 | 7 | 0 | 4.46 | 14 | 16.0 | 0.0 | ... | 86 | 253 | 3 | 0.38 | 29 | 0.36 | 0.034 | 0.9 | 0.08 | 0.3 | . 4 Milk | Milk, calcium fortified, whole | 11111150 | 0 | 7 | 0 | 4.67 | 12 | 17.8 | 0.0 | ... | 101 | 150 | 38 | 0.41 | 32 | 0.54 | 0.061 | 0.0 | 0.05 | 0.3 | . 5 rows × 38 columns . # histogram food_df[&#39;Data.Carbohydrate&#39;].plot.hist(bins=20, title=&#39;Carbohydrate Contained in Food (in grams)&#39;, figsize=(8,8), color=&#39;orange&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Carbohydrate Contained in Food (in grams)&#39;}, ylabel=&#39;Frequency&#39;&gt; .",
            "url": "https://jhuang00.github.io/dh140-blog/fastpages/jupyter/2022/03/06/Assignment05.html",
            "relUrl": "/fastpages/jupyter/2022/03/06/Assignment05.html",
            "date": " • Mar 6, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jhuang00.github.io/dh140-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jhuang00.github.io/dh140-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jhuang00.github.io/dh140-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jhuang00.github.io/dh140-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}